{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# yay models\n",
    "import xgboost as xgb\n",
    "import graphviz\n",
    "\n",
    "# used for train/test splits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# used to impute mean for data\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# models to test\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.svm as svm\n",
    "import sklearn.ensemble as ensemble\n",
    "\n",
    "# used to calculate AUROC/accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# used to create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "# default colours for prettier plots\n",
    "col = [[0.9047, 0.1918, 0.1988],\n",
    "    [0.2941, 0.5447, 0.7494],\n",
    "    [0.3718, 0.7176, 0.3612],\n",
    "    [1.0000, 0.5482, 0.1000],\n",
    "    [0.4550, 0.4946, 0.4722],\n",
    "    [0.6859, 0.4035, 0.2412],\n",
    "    [0.9718, 0.5553, 0.7741],\n",
    "    [0.5313, 0.3359, 0.6523]];\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the equations used\n",
    "def pao2_nonlinear(s):\n",
    "    # Severinghaus 1979\n",
    "    \n",
    "    # prevent divide by 0 errors\n",
    "    s = np.where(s ==   0,  0.01, s)\n",
    "    s = np.where(s == 100, 99.99, s)\n",
    "    \n",
    "    # convert input from % to fraction\n",
    "    s = s / 100.0\n",
    "    t = 11700 / (1/s - 1)\n",
    "    \n",
    "    p1 = t + np.sqrt( 125000 + np.power(t,2))\n",
    "    idxNeg = p1 < 0\n",
    "    p1 = np.power(abs(p1), float(1)/3)\n",
    "    p1 = np.where(idxNeg, -p1, p1)\n",
    "    \n",
    "    p2 = t - np.sqrt( 125000 + np.power(t,2))\n",
    "    idxNeg = p2 < 0\n",
    "    p2 = np.power(abs(p2), float(1)/3)\n",
    "    p2 = np.where(idxNeg, -p2, p2)\n",
    "    \n",
    "    p = p1 + p2\n",
    "    \n",
    "    return p\n",
    "\n",
    "def pao2_loglinear(s,f):\n",
    "    # Pandharipande 2009\n",
    "    \n",
    "    # calculate log (base 10...) pao2/fio2 ratio\n",
    "    p = 0.48 + (0.78 * np.log10(s/f))\n",
    "    \n",
    "    # convert from log10(pf) to pao2\n",
    "    p = np.power(10, p) * f\n",
    "    \n",
    "    return p\n",
    "\n",
    "def pao2_loglinear_peep(s,f,peep):\n",
    "    \n",
    "    if peep < 8:\n",
    "        PF = np.power(10, 0.06 + 0.94 * np.log10(s/f)) # < 8\n",
    "        \n",
    "    elif peep <= 12:\n",
    "        PF = np.power(10, -0.13 + 1.01 * np.log10(s/f)) # 8-12\n",
    "    \n",
    "    else:\n",
    "        PF = np.power(10, -0.47 + 1.17 * np.log10(s/f)) # > 12\n",
    "        \n",
    "        \n",
    "    return PF * f\n",
    "    \n",
    "    \n",
    "    \n",
    "def pao2_linear(s,f):\n",
    "    # Rice 2007\n",
    "    \n",
    "    # calculate log pao2/fio2 ratio\n",
    "    p = (s/f - 64.0)/0.84\n",
    "    \n",
    "    # convert from pf to pao2\n",
    "    p = p * f\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the equations against each other\n",
    "\n",
    "xi = range(100)\n",
    "\n",
    "eq1 = [pao2_nonlinear(x) for x in xi]\n",
    "eq2 = [pao2_loglinear(x, 0.2089) for x in xi]\n",
    "eq3 = [pao2_linear(x, 0.2089) for x in xi]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(eq1, xi, linestyle=':',linewidth=2,color='black')\n",
    "plt.plot(eq2, xi, linestyle='--',linewidth=2,color='red')\n",
    "plt.plot(eq3, xi, linestyle='-',linewidth=2,color='blue')\n",
    "\n",
    "plt.xlabel('SpO2')\n",
    "plt.ylabel('PaO2')\n",
    "plt.legend(['Non-linear','Log-linear','Linear'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a database connection\n",
    "\n",
    "# below config used on pc70\n",
    "sqluser = 'alistairewj'\n",
    "dbname = 'eicu'\n",
    "schema_name = 'eicu'\n",
    "\n",
    "# Connect to local postgres version of mimic\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to ' + schema_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "cur.execute('SET search_path to ' + schema_name)\n",
    "query = \\\n",
    "\"\"\"\n",
    "select * from PAO2MODELDATA;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query,con)\n",
    "df.describe()\n",
    "#df = pd.read_csv('pao2-model.csv.gz', compression='gzip')\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter out bad data\n",
    "idxIgnore = np.any([df.fio2.values < 20, df.fio2.values > 100], axis=0)\n",
    "\n",
    "# extract data\n",
    "y = df.pao2[~idxIgnore].values\n",
    "X_names = ['sao2', 'fio2', 'vasopressor']\n",
    "\n",
    "# create an iterator to get index of these names\n",
    "idx = [i for i in range(df.columns.values.size) if df.columns[i] in X_names]\n",
    "\n",
    "# get feature/predictor matrix as numpy array\n",
    "X = df[idx].values\n",
    "X = X[~idxIgnore,:]\n",
    "# create the header from the column index we made earlier\n",
    "X_header = [df.columns[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a box plot of our data\n",
    "# there is some bug with the date type being different in python/pandas\n",
    "# it messes up the boxplot function\n",
    "# so we extract the data with only the names\n",
    "# this removes charttime which was causing us trouble\n",
    "#df0 = pd.DataFrame.from_records(df, columns=X_names)\n",
    "\n",
    "plt.figure()\n",
    "df.boxplot(return_type='axes', vert=False)\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([0,200])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try a linear regression\n",
    "model = lm.LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "yhat_lr = model.predict(X_test)\n",
    "print('RMSE: {}').format( np.sqrt( np.mean( np.square(yhat_lr - y_test) ) ) )\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_test, y_test-yhat_lr, linestyle='none',marker='x')\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Difference (Truth - Prediction)')\n",
    "plt.show()\n",
    "\n",
    "# would be nice to see the plot with mini BoxPlots @ 50, 100, 150, 200, etc instead of a bunch of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.DMatrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_xgboost(X_train, y_train, X_test, y_test, feature_names=X_header):\n",
    "    # try xgboost\n",
    "    dtrain = xgb.DMatrix( X_train, label=y_train, feature_names=X_header)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test, feature_names=X_header)\n",
    "\n",
    "    # parameters\n",
    "    param = {'silent':1,\n",
    "             #'bst:eta':1,\n",
    "             'objective':'reg:linear'}\n",
    "    param['nthread'] = 4\n",
    "\n",
    "    bst = xgb.train( param, dtrain, 10 )\n",
    "    \n",
    "    yhat = bst.predict(dtest)\n",
    "    return [yhat, bst]\n",
    "    \n",
    "def try_lr(X_train, y_train, X_test, y_test, feature_names=X_header):\n",
    "    # try xgboost\n",
    "    model = lm.LinearRegression(fit_intercept=True)\n",
    "    model.fit(X_train,y_train)\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try xgboost\n",
    "dtrain = xgb.DMatrix( X_train, label=y_train, feature_names=X_header)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, feature_names=X_header)\n",
    "\n",
    "# parameters\n",
    "param = {'silent':1,\n",
    "         #'bst:eta':1,\n",
    "         'objective':'reg:linear'}\n",
    "param['nthread'] = 4\n",
    "\n",
    "bst = xgb.train( param, dtrain, 10 )\n",
    "\n",
    "# bst.save_model('pafi-xgboost-0001.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yhat_xg = bst.predict(dtest)\n",
    "print('RMSE: {}').format( np.sqrt( np.mean( np.square(yhat_xg - y_test) ) ) )\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_test, y_test-yhat_lr, linestyle='none',marker='x')\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Difference (Truth - Prediction)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xgb.to_graphviz(bst, num_trees=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try an SVM\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "score = 'mean_squared_error'\n",
    "\n",
    "print(\"\\n# Tuning hyper-parameters for %s\" % score)\n",
    "clf = GridSearchCV(svm.NuSVR(), tuned_parameters, cv=5,\n",
    "                   scoring=score)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "print(\"\\nGrid scores on development set:\")\n",
    "for params, mean_score, scores in clf.grid_scores_:\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean_score, scores.std() * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yhat_svm = clf.predict(X_test)\n",
    "print('RMSE: {}').format( np.sqrt( np.mean( np.square(yhat_svm - y_test) ) ) )\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_test, y_test-yhat_lr, linestyle='none',marker='x')\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Difference (Truth - Prediction)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_test, yhat_lr, linestyle='none',marker='x')\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patients with SpO2 <= 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter out bad data and SpO2s > 96\n",
    "idxIgnore = np.any([df.fio2.values < 20, df.fio2.values > 100, df.sao2.values > 96], axis=0)\n",
    "\n",
    "# extract data\n",
    "y = df.pao2[~idxIgnore].values\n",
    "X_names = ['sao2', 'fio2', 'vasopressor']\n",
    "\n",
    "# create an iterator to get index of these names\n",
    "idx = [i for i in range(df.columns.values.size) if df.columns[i] in X_names]\n",
    "\n",
    "# get feature/predictor matrix as numpy array\n",
    "X = df[idx].values\n",
    "X = X[~idxIgnore,:]\n",
    "\n",
    "# create the header from the column index we made earlier\n",
    "X_header = [df.columns[i] for i in idx]\n",
    "\n",
    "# Add in the interaction term\n",
    "z = X[:, X_header.index('sao2')] / X[:, X_header.index('fio2')]\n",
    "X = np.column_stack([X, z])\n",
    "X_header.extend(['sao2fio2'])\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize some of the relationships\n",
    "idx = 0\n",
    "plt.figure()\n",
    "plt.plot(X[:,idx], y, linestyle='none',marker='x',color='b')\n",
    "plt.xlabel(X_header[idx])\n",
    "plt.ylabel('PaO2')\n",
    "plt.title('PaO2 against a covariate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize some of the relationships\n",
    "idx = 1\n",
    "plt.figure()\n",
    "plt.plot(X[:,idx], y, linestyle='none',marker='x',color='b')\n",
    "plt.xlabel(X_header[idx])\n",
    "plt.ylabel('PaO2')\n",
    "plt.title('PaO2 against a covariate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize some of the relationships\n",
    "idx = 3\n",
    "idxVaso = X[:,2]==1\n",
    "plt.figure()\n",
    "plt.plot(X[~idxVaso,idx], y[~idxVaso], linestyle='none',marker='x',color='b')\n",
    "plt.plot(X[idxVaso,idx], y[idxVaso], linestyle='none',marker='x',color='r')\n",
    "plt.xlabel(X_header[idx])\n",
    "plt.ylabel('PaO2')\n",
    "plt.title('PaO2 against a covariate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try a linear regression\n",
    "model = lm.LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "yhat_lr = model.predict(X_test)\n",
    "print('RMSE: {}').format( np.sqrt( np.mean( np.square(yhat_lr - y_test) ) ) )\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_test, y_test - yhat_lr + 90, linestyle='none',marker='x')\n",
    "plt.plot([0,500], [0,500], linestyle='--',color='black')\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Truth - Prediction')\n",
    "plt.show()\n",
    "\n",
    "# would be nice to see the plot with mini BoxPlots @ 50, 100, 150, 200, etc instead of a bunch of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Robustly fit linear model with RANSAC algorithm\n",
    "model_ransac = lm.RANSACRegressor(lm.LinearRegression(fit_intercept=True))\n",
    "model_ransac.fit(X_train,y_train)\n",
    "inlier_mask = model_ransac.inlier_mask_\n",
    "outlier_mask = np.logical_not(inlier_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yhat_robust_train = model_ransac.predict(X_train)\n",
    "yhat_robust = model_ransac.predict(X_test)\n",
    "# for some reason ransac outputs an Nx1 array, rather than an N length array... subtracting Nx1 by an N length array gives a matrix\n",
    "# numpy confuses me sometimes...\n",
    "yhat_robust_train = np.reshape(yhat_robust_train, yhat_robust_train.size)\n",
    "yhat_robust = np.reshape(yhat_robust, yhat_robust.size)\n",
    "print('RMSE: Normal {}, Robust: {}').format( np.sqrt( np.mean( np.square(yhat_lr - y_test) ) ), np.sqrt( np.mean( np.square(yhat_robust - y_test) ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare estimated coefficients\n",
    "print(\"Estimated coefficients (normal, RANSAC):\")\n",
    "for i in range(model.coef_.size):\n",
    "    print('{:15s}\\t{:2.4f}\\t\\t{:2.4f}').format(X_header[i],model.coef_[i], model_ransac.estimator_.coef_[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training set - has outlier masks\n",
    "plt.figure()\n",
    "plt.plot(y_train[inlier_mask], y_train[inlier_mask] - yhat_robust_train[inlier_mask], '.b', label='Inliers')\n",
    "plt.plot(y_train[outlier_mask], y_train[outlier_mask] - yhat_robust_train[outlier_mask], '.r', label='Outliers')\n",
    "plt.plot([0,500], [0,500], linestyle='--',color='black')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test set\n",
    "plt.figure()\n",
    "plt.plot(y_test, y_test - yhat_robust, linestyle='none',marker='x',color='b')\n",
    "plt.plot(y_test, y_test - yhat_robust, linestyle='none',marker='x',color='g')\n",
    "plt.plot([0,500], [0,500], linestyle='--',color='black')\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Truth - Prediction')\n",
    "plt.title('Test set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try an SVM\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "score = 'mean_squared_error'\n",
    "\n",
    "print(\"\\n# Tuning hyper-parameters for %s\" % score)\n",
    "clf = GridSearchCV(svm.NuSVR(), tuned_parameters, cv=5,\n",
    "                   scoring=score)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "print(\"\\nGrid scores on development set:\")\n",
    "for params, mean_score, scores in clf.grid_scores_:\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean_score, scores.std() * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yhat_svm = clf.predict(X_test)\n",
    "print('RMSE: {}').format( np.sqrt( np.mean( np.square(yhat_svm - y_test) ) ) )\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_test, y_test-yhat_lr, linestyle='none',marker='x')\n",
    "plt.plot([0,500], [0,500], linestyle='--',color='black')\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Difference (Truth - Prediction)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reproduce the Rice2007 plot\n",
    "sao2 = X_test[:, X_header.index('sao2')]\n",
    "fio2 = X_test[:, X_header.index('fio2')] / 100\n",
    "sf = sao2 / fio2\n",
    "pf = y_test / fio2\n",
    "\n",
    "\n",
    "# use their linear equation\n",
    "pf1 = pao2_nonlinear(sao2) / fio2\n",
    "pf2 = pao2_loglinear(sao2,fio2) / fio2\n",
    "pf3 = pao2_linear(sao2,fio2) / fio2\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(pf,  sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[6])\n",
    "plt.plot(pf1, sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[1])\n",
    "plt.plot(pf2, sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[2])\n",
    "plt.plot(pf3, sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[3])\n",
    "\n",
    "plt.plot([0,500], [0,500], linestyle='--',color='black')\n",
    "plt.xlabel('PaO2/FiO2',fontsize=14)\n",
    "plt.ylabel('SaO2/FiO2',fontsize=14)\n",
    "\n",
    "\n",
    "plt.legend(['Truth',\n",
    "            'Non-linear: ' + \"%2.1f\" % np.sqrt ( ( np.square(pf1-pf) ).mean() ),\n",
    "            'Log-linear:' + \"%2.1f\" % np.sqrt ( ( np.square(pf2-pf) ).mean() ),\n",
    "            'Linear:' + \"%2.1f\" % np.sqrt ( ( np.square(pf3-pf) ).mean() )],loc='best')\n",
    "plt.xlim([0,500])\n",
    "plt.ylim([0,500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model using non-linear imputation as a feature\n",
    "\n",
    "Let's try a normal regression with non-linear imputation as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter out bad data and SpO2s > 96\n",
    "idxIgnore = np.any([df.fio2.values < 20, df.fio2.values > 100, df.sao2.values > 96], axis=0)\n",
    "\n",
    "# extract data\n",
    "y = df.pao2[~idxIgnore].values\n",
    "X_names = ['sao2', 'fio2', 'vasopressor']\n",
    "\n",
    "# create an iterator to get index of these names\n",
    "idx = [i for i in range(df.columns.values.size) if df.columns[i] in X_names]\n",
    "\n",
    "# get feature/predictor matrix as numpy array\n",
    "X = df[idx].values\n",
    "X = X[~idxIgnore,:]\n",
    "\n",
    "# create the header from the column index we made earlier\n",
    "X_header = [df.columns[i] for i in idx]\n",
    "\n",
    "# Add in the prediction from the non-linear equation\n",
    "z = pao2_nonlinear(X[:, X_header.index('sao2')]) / X[:, X_header.index('fio2')]\n",
    "X = np.column_stack([X, z])\n",
    "X_header.extend(['PAO2FIO2_nonlinear'])\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# using the fixed equations (linear/loglinear/nonlinear), calculate the pao2\n",
    "sao2 = X_test[:, X_header.index('sao2')]\n",
    "fio2 = X_test[:, X_header.index('fio2')] / 100\n",
    "\n",
    "pf1 = pao2_nonlinear(sao2) / fio2\n",
    "pf2 = pao2_loglinear(sao2,fio2) / fio2\n",
    "pf3 = pao2_linear(sao2,fio2) / fio2\n",
    "\n",
    "# ground truth\n",
    "sf = sao2 / fio2\n",
    "pf = y_test / fio2\n",
    "\n",
    "# try a linear regression\n",
    "model = lm.LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train,y_train)\n",
    "yhat_lr = model.predict(X_test)\n",
    "pf_pred = yhat_lr / fio2\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(pf,  sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[6])\n",
    "plt.plot(pf3, sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[0])\n",
    "plt.plot(pf2, sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[1])\n",
    "plt.plot(pf1, sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[2])\n",
    "plt.plot(pf_pred, sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[3])\n",
    "\n",
    "plt.plot([0,500], [0,500], linestyle='--',color='black')\n",
    "plt.xlabel('PaO2/FiO2',fontsize=14)\n",
    "plt.ylabel('SaO2/FiO2',fontsize=14)\n",
    "\n",
    "\n",
    "plt.legend(['Truth',\n",
    "            'Linear:' + \"%2.1f\" % np.sqrt ( ( np.square(pf3-pf) ).mean() ),\n",
    "            'Log-linear:' + \"%2.1f\" % np.sqrt ( ( np.square(pf2-pf) ).mean() ),\n",
    "            'Non-linear: ' + \"%2.1f\" % np.sqrt ( ( np.square(pf1-pf) ).mean() ),\n",
    "            'Prediction:' + '%2.1f' % np.sqrt( ( np.square(pf_pred-pf) ).mean())],loc='best')\n",
    "plt.xlim([0,500])\n",
    "plt.ylim([0,500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter out bad data and SpO2s > 96\n",
    "idxIgnore = np.any([df.fio2.values < 20, df.fio2.values > 100, df.sao2.values > 96], axis=0)\n",
    "\n",
    "# extract data\n",
    "y = df.pao2[~idxIgnore].values\n",
    "X_names = ['sao2', 'fio2', 'vasopressor']\n",
    "\n",
    "# create an iterator to get index of these names\n",
    "idx = [i for i in range(df.columns.values.size) if df.columns[i] in X_names]\n",
    "\n",
    "# get feature/predictor matrix as numpy array\n",
    "X = df[idx].values\n",
    "X = X[~idxIgnore,:]\n",
    "\n",
    "# create the header from the column index we made earlier\n",
    "X_header = [df.columns[i] for i in idx]\n",
    "\n",
    "# Add in the prediction from the non-linear equation\n",
    "z = pao2_nonlinear(X[:, X_header.index('sao2')]) / X[:, X_header.index('fio2')]\n",
    "X = np.column_stack([X, z])\n",
    "X_header.extend(['PAO2FIO2_nonlinear'])\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# using the fixed equations (linear/loglinear/nonlinear), calculate the pao2\n",
    "sao2 = X_test[:, X_header.index('sao2')]\n",
    "fio2 = X_test[:, X_header.index('fio2')] / 100\n",
    "\n",
    "pf1 = pao2_nonlinear(sao2) / fio2\n",
    "pf2 = pao2_loglinear(sao2,fio2) / fio2\n",
    "pf3 = pao2_linear(sao2,fio2) / fio2\n",
    "\n",
    "# ground truth\n",
    "sf = sao2 / fio2\n",
    "pf = y_test / fio2\n",
    "\n",
    "# try xg\n",
    "dtrain = xgb.DMatrix( X_train, label=y_train, feature_names=X_header)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, feature_names=X_header)\n",
    "\n",
    "# parameters\n",
    "param = {'silent':1,\n",
    "         #'bst:eta':1,\n",
    "         'objective':'reg:linear'}\n",
    "param['nthread'] = 4\n",
    "\n",
    "bst = xgb.train( param, dtrain, 10 )\n",
    "yhat_xg = bst.predict(dtest)\n",
    "pf_pred = yhat_xg / fio2\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(pf,  sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[6])\n",
    "plt.plot(pf3, sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[0])\n",
    "plt.plot(pf2, sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[1])\n",
    "plt.plot(pf1, sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[2])\n",
    "plt.plot(pf_pred, sf, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[3])\n",
    "\n",
    "plt.plot([0,500], [0,500], linestyle='--',color='black')\n",
    "plt.xlabel('PaO2/FiO2',fontsize=14)\n",
    "plt.ylabel('SaO2/FiO2',fontsize=14)\n",
    "\n",
    "\n",
    "plt.legend(['Truth',\n",
    "            'Linear:' + \"%2.1f\" % np.sqrt ( ( np.square(pf3-pf) ).mean() ),\n",
    "            'Log-linear:' + \"%2.1f\" % np.sqrt ( ( np.square(pf2-pf) ).mean() ),\n",
    "            'Non-linear: ' + \"%2.1f\" % np.sqrt ( ( np.square(pf1-pf) ).mean() ),\n",
    "            'Prediction:' + '%2.1f' % np.sqrt( ( np.square(pf_pred-pf) ).mean())],loc='best')\n",
    "plt.xlim([0,500])\n",
    "plt.ylim([0,500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot PaO2/FiO2 (truth) against the predictions\n",
    "\n",
    "# add some jitter\n",
    "def add_jitter(x):\n",
    "    stdev = .01*(max(x)-min(x))\n",
    "    return x + np.random.randn(len(x)) * stdev\n",
    "\n",
    "def jitter(x, y, markersize=10, color='b', marker='o', linewidth=2, **kwargs):\n",
    "    return plt.plot(add_jitter(x), add_jitter(y), markersize=markersize, color=color, marker=marker, linewidth=linewidth, **kwargs)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "jitter(pf, pf3, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[0])\n",
    "jitter(pf, pf2, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[1])\n",
    "jitter(pf, pf1, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[2])\n",
    "jitter(pf, pf_pred, linestyle='none',marker='.',linewidth=2,markersize=10,color=col[3])\n",
    "\n",
    "plt.plot([0,500], [0,500], linestyle='--',color='black')\n",
    "plt.xlabel('PaO2/FiO2 (truth)',fontsize=14)\n",
    "plt.ylabel('PaO2/FiO2 (predicted)',fontsize=14)\n",
    "\n",
    "\n",
    "plt.legend(['Linear:' + \"%2.1f\" % np.sqrt ( ( np.square(pf3-pf) ).mean() ),\n",
    "            'Log-linear:' + \"%2.1f\" % np.sqrt ( ( np.square(pf2-pf) ).mean() ),\n",
    "            'Non-linear: ' + \"%2.1f\" % np.sqrt ( ( np.square(pf1-pf) ).mean() ),\n",
    "            'Prediction:' + '%2.1f' % np.sqrt( ( np.square(pf_pred-pf) ).mean())],loc='best')\n",
    "plt.xlim([0,500])\n",
    "plt.ylim([0,500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pf_all = np.column_stack([pf3, pf2, pf1, pf_pred])\n",
    "pf_header = ['Linear:' + \"%2.1f\" % np.sqrt ( ( np.square(pf3-pf) ).mean() ),\n",
    "            'Log-linear:' + \"%2.1f\" % np.sqrt ( ( np.square(pf2-pf) ).mean() ),\n",
    "            'Non-linear: ' + \"%2.1f\" % np.sqrt ( ( np.square(pf1-pf) ).mean() ),\n",
    "            'Prediction:' + '%2.1f' % np.sqrt( ( np.square(pf_pred-pf) ).mean())]\n",
    "\n",
    "# initialize the locations of each box\n",
    "pf_grp = np.asarray(range(20))*20+20\n",
    "\n",
    "# initialize the values of the box plot\n",
    "pf_mu = np.zeros( [ pf_grp.size, pf_all.shape[1] ] )\n",
    "pf_med = np.zeros( [ pf_grp.size, pf_all.shape[1] ] )\n",
    "pf_25 = np.zeros( [ pf_grp.size, pf_all.shape[1] ] )\n",
    "pf_75 = np.zeros( [ pf_grp.size, pf_all.shape[1] ] )\n",
    "pf_iqr = np.zeros( [ pf_grp.size, pf_all.shape[1] ] )\n",
    "pf_min = np.zeros( [ pf_grp.size, pf_all.shape[1] ] )\n",
    "pf_max = np.zeros( [ pf_grp.size, pf_all.shape[1] ] )\n",
    "\n",
    "for i in range(pf_grp.size-1):\n",
    "    for p in range(pf_all.shape[1]):\n",
    "        tmp = pf_all[:,p]\n",
    "        tmp = tmp[ (pf >= pf_grp[i]) & (pf < pf_grp[i+1]) ]\n",
    "        tmp = tmp[ ~np.isnan(tmp)]\n",
    "        if tmp.size > 1:\n",
    "            pf_mu[i,p] = np.mean(tmp)\n",
    "            pf_med[i,p] = np.median(tmp)\n",
    "            pf_25[i,p] = np.percentile(tmp,25)\n",
    "            pf_75[i,p] = np.percentile(tmp,75)\n",
    "            pf_iqr[i,p] = np.percentile(tmp,75) - np.percentile(tmp,25)\n",
    "            pf_min[i,p] = np.min(tmp)\n",
    "            pf_max[i,p] = np.max(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,12])\n",
    "\n",
    "p=0\n",
    "P = pf_all.shape[1] # number of boxplots\n",
    "boxWidth = (pf_grp[1] - pf_grp[0]) * 1/P \n",
    "\n",
    "for p in range(P):\n",
    "    for i in range(pf_grp.size - 1):\n",
    "\n",
    "        boxStart =  pf_grp[i] + p*boxWidth\n",
    "        boxEnd = pf_grp[i] + (p+1)*boxWidth\n",
    "        boxMed = (boxEnd - boxStart)/2.0 + boxStart\n",
    "\n",
    "        # horizontal lines\n",
    "        plt.plot( [boxStart, boxEnd], [pf_25[i,p], pf_25[i,p]], color=col[p], linewidth=2 )\n",
    "        plt.plot( [boxStart, boxEnd], [pf_75[i,p], pf_75[i,p]], color=col[p], linewidth=2 )\n",
    "\n",
    "        # vertical lines\n",
    "        plt.plot( [boxStart, boxStart], [pf_25[i,p], pf_75[i,p]], color=col[p], linewidth=2 )\n",
    "        plt.plot( [boxEnd, boxEnd], [pf_25[i,p], pf_75[i,p]], color=col[p], linewidth=2 )\n",
    "\n",
    "        # medians\n",
    "        plt.plot( boxMed, pf_med[i,p], color=col[p], linewidth=2, marker='o' )\n",
    "\n",
    "        # whiskers (option 1)\n",
    "        #plt.plot( [medLoc, medLoc], [pf_75[i,p], pf_75[i,p]+pf_iqr[i,p]*1.5], color=col[p], linewidth=2, linestyle='--' )\n",
    "        #plt.plot( [medLoc, medLoc], [pf_25[i,p]-pf_iqr[i,p]*1.5, pf_25[i,p]], color=col[p], linewidth=2, linestyle='--' )\n",
    "\n",
    "        # whiskers (option 2)\n",
    "        plt.plot( [boxMed, boxMed], [pf_75[i,p], pf_max[i,p]], color=col[p], linewidth=2, linestyle='--' )\n",
    "        plt.plot( [boxMed, boxMed], [pf_25[i,p], pf_min[i,p]], color=col[p], linewidth=2, linestyle='--' )\n",
    "\n",
    "    plt.text(25, 480 - p*20, pf_header[p], color=col[p],fontsize=16, fontweight='bold')\n",
    "    \n",
    "plt.plot([0,400],[0,400],linestyle='--',linewidth=1.5, color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with more of the variables\n",
    "\n",
    "Now let's try a regression with temperature, etc. See how we do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add in dummy variables\n",
    "X_names_dummy = ['o2device']\n",
    "df_dummy = pd.get_dummies(df['o2device'], prefix='o2_')\n",
    "idx = [i for i in range(df_dummy.columns.values.size)]\n",
    "X_dummy = df_dummy[idx].values\n",
    "X_dummy = X_dummy[~idxIgnore,:]\n",
    "X_header_dummy = [df_dummy.columns[i] for i in idx]\n",
    "\n",
    "D = X_dummy.shape[1]\n",
    "idxKeepDummy = np.ones([D,1])\n",
    "for d in range(D):\n",
    "    if np.sum(X_dummy[:,d]) < 100:\n",
    "        idxKeepDummy[d] = 0\n",
    "        \n",
    "        \n",
    "idxKeepDummy = [i for i in range(D) if idxKeepDummy[i] == 1]\n",
    "\n",
    "#X = np.hstack([X, X_dummy[:,idxKeepDummy]])\n",
    "#X_header.extend([X_header_dummy[i] for i, ivar in enumerate(idxKeepDummy)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#TODO: try again with more datas\n",
    "\n",
    "# filter out bad data and SpO2s > 96\n",
    "idxIgnore = np.any([df.fio2.values < 20, df.fio2.values > 100, df.sao2.values > 96], axis=0)\n",
    "\n",
    "# extract data\n",
    "y = df.pao2[~idxIgnore].values\n",
    "X_names = ['sao2', 'fio2', 'vasopressor','peep','tidalvolume','peakpressure']\n",
    "\n",
    "# create an iterator to get index of these names\n",
    "idx = [i for i in range(df.columns.values.size) if df.columns[i] in X_names]\n",
    "\n",
    "# get feature/predictor matrix as numpy array\n",
    "X = df[idx].values\n",
    "X = X[~idxIgnore,:]\n",
    "\n",
    "# create the header from the column index we made earlier\n",
    "X_header = [df.columns[i] for i in idx]\n",
    "\n",
    "# Add in the sao2/fio2\n",
    "z = X[:, X_header.index('sao2')] / X[:, X_header.index('fio2')]\n",
    "X = np.column_stack([X, z])\n",
    "X_header.extend(['sao2fio2'])\n",
    "\n",
    "# Add in the predicted pao2 from the non-linear equation\n",
    "z = pao2_nonlinear(X[:, X_header.index('sao2')]) # / X[:, X_header.index('fio2')]\n",
    "X = np.column_stack([X, z])\n",
    "X_header.extend(['pao2_nonlinear'])\n",
    "\n",
    "## Add in the predicted pao2/fio2 from the non-linear equation\n",
    "#z = pao2_nonlinear(X[:, X_header.index('sao2')])  / X[:, X_header.index('fio2')]\n",
    "#X = np.column_stack([X, z])\n",
    "#X_header.extend(['pao2fio2_nonlinear'])\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X_train)\n",
    "\n",
    "# using the fixed equations (linear/loglinear/nonlinear), calculate the pao2\n",
    "sao2 = X_test[:, X_header.index('sao2')]\n",
    "fio2 = X_test[:, X_header.index('fio2')] / 100\n",
    "\n",
    "pf1 = pao2_nonlinear(sao2) / fio2\n",
    "pf2 = pao2_loglinear(sao2,fio2) / fio2\n",
    "pf3 = pao2_linear(sao2,fio2) / fio2\n",
    "\n",
    "# ground truth\n",
    "sf = sao2 / fio2\n",
    "pf = y_test / fio2\n",
    "\n",
    "\n",
    "# try a linear regression\n",
    "fio2_train = X_train[:, X_header.index('fio2')] / 100\n",
    "model = lm.LinearRegression(fit_intercept=True)\n",
    "model.fit( imp.transform(X_train) , y_train )\n",
    "yhat_lr = model.predict(imp.transform(X_test))\n",
    "pf_pred = yhat_lr / fio2\n",
    "\n",
    "# print out of the model coefficients\n",
    "mdlcoef = model.coef_.flatten()\n",
    "\n",
    "# sort by value of coefficient\n",
    "sort_indices = np.argsort(mdlcoef, axis=0)\n",
    "mdlcoef = mdlcoef[sort_indices]\n",
    "\n",
    "# also create a labels vector which is sorted\n",
    "lbls = [X_header[i] for i in sort_indices]\n",
    "\n",
    "print('{:10.5f} {}').format(model.intercept_, 'intercept')\n",
    "for i in range(len(X_header)):\n",
    "    print('{:10.5f} {}').format(mdlcoef[i], lbls[i])\n",
    "\n",
    "plt.figure(figsize=[15,12])\n",
    "\n",
    "p=0\n",
    "P = pf_all.shape[1] # number of boxplots\n",
    "boxWidth = (pf_grp[1] - pf_grp[0]) * 1/P \n",
    "\n",
    "for p in range(P):\n",
    "    for i in range(pf_grp.size - 1):\n",
    "\n",
    "        boxStart =  pf_grp[i] + p*boxWidth\n",
    "        boxEnd = pf_grp[i] + (p+1)*boxWidth\n",
    "        boxMed = (boxEnd - boxStart)/2.0 + boxStart\n",
    "\n",
    "        # horizontal lines\n",
    "        plt.plot( [boxStart, boxEnd], [pf_25[i,p], pf_25[i,p]], color=col[p], linewidth=2 )\n",
    "        plt.plot( [boxStart, boxEnd], [pf_75[i,p], pf_75[i,p]], color=col[p], linewidth=2 )\n",
    "\n",
    "        # vertical lines\n",
    "        plt.plot( [boxStart, boxStart], [pf_25[i,p], pf_75[i,p]], color=col[p], linewidth=2 )\n",
    "        plt.plot( [boxEnd, boxEnd], [pf_25[i,p], pf_75[i,p]], color=col[p], linewidth=2 )\n",
    "\n",
    "        # medians\n",
    "        plt.plot( boxMed, pf_med[i,p], color=col[p], linewidth=2, marker='o' )\n",
    "\n",
    "        # whiskers (option 1)\n",
    "        #plt.plot( [medLoc, medLoc], [pf_75[i,p], pf_75[i,p]+pf_iqr[i,p]*1.5], color=col[p], linewidth=2, linestyle='--' )\n",
    "        #plt.plot( [medLoc, medLoc], [pf_25[i,p]-pf_iqr[i,p]*1.5, pf_25[i,p]], color=col[p], linewidth=2, linestyle='--' )\n",
    "\n",
    "        # whiskers (option 2)\n",
    "        plt.plot( [boxMed, boxMed], [pf_75[i,p], pf_max[i,p]], color=col[p], linewidth=2, linestyle='--' )\n",
    "        plt.plot( [boxMed, boxMed], [pf_25[i,p], pf_min[i,p]], color=col[p], linewidth=2, linestyle='--' )\n",
    "\n",
    "    plt.text(25, 480 - p*20, pf_header[p], color=col[p],fontsize=16, fontweight='bold')\n",
    "    \n",
    "plt.plot([0,400],[0,400],linestyle='--',linewidth=1.5, color='black')\n",
    "\n",
    "plt.xlabel('PaO2/FiO2 (truth)',fontsize=14)\n",
    "plt.ylabel('PaO2/FiO2 (predicted)',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_boxplot(pf, pf_dict):\n",
    "    # add in the elements from the dictionary\n",
    "    header = pf_dict.keys()\n",
    "    pf_header = [ hdr + ': ' + \"%2.1f\" % np.sqrt ( ( np.square(pf_dict[hdr]-pf) ).mean() )\n",
    "             for n, hdr in enumerate(header)]\n",
    "    \n",
    "    P = len(header)\n",
    "    \n",
    "    # initialize the locations of each box\n",
    "    pf_grp = (np.asarray(range(30))+1)*15\n",
    "    G = pf_grp.size-1 # number of groups of PaO2/FiO2\n",
    "\n",
    "    # initialize the values of the box plot\n",
    "    pf_mu = np.zeros( [ G, P ] )\n",
    "    pf_med = np.zeros( [ G, P ] )\n",
    "    pf_25 = np.zeros( [ G, P ] )\n",
    "    pf_75 = np.zeros( [ G, P ] )\n",
    "    pf_iqr = np.zeros( [ G, P ] )\n",
    "    pf_min = np.zeros( [ G, P ] )\n",
    "    pf_max = np.zeros( [ G, P ] )\n",
    "    # number of observations\n",
    "    pf_num = np.zeros( [ G, P ] )\n",
    "\n",
    "    for i in range(G):\n",
    "        for p in range(P):\n",
    "            tmp = pf_dict[header[p]]\n",
    "            tmp = tmp[ (pf >= pf_grp[i]) & (pf < pf_grp[i+1]) ]\n",
    "            tmp = tmp[ ~np.isnan(tmp)]\n",
    "            pf_num[i,p] = tmp.size \n",
    "            if tmp.size > 1:\n",
    "                pf_mu[i,p] = np.mean(tmp)\n",
    "                pf_med[i,p] = np.median(tmp)\n",
    "                pf_25[i,p] = np.percentile(tmp,25)\n",
    "                pf_75[i,p] = np.percentile(tmp,75)\n",
    "                pf_iqr[i,p] = np.percentile(tmp,75) - np.percentile(tmp,25)\n",
    "                pf_min[i,p] = np.min(tmp)\n",
    "                pf_max[i,p] = np.max(tmp)\n",
    "\n",
    "    # create axis which is middle of the bar\n",
    "    pf_plt = [ pf_grp[i] + (pf_grp[i+1] - pf_grp[i]) / 2 for i in range(pf_grp.size-1) ]\n",
    "    \n",
    "    #================ NORMAL PLOT =======================#\n",
    "    plt.figure(figsize=[15,12])\n",
    "\n",
    "    boxWidth = (pf_grp[1] - pf_grp[0]) * 1/P \n",
    "\n",
    "\n",
    "    for p in range(P):\n",
    "        plt.plot( pf_plt, pf_med[:,p], color=col[p], linewidth=2, linestyle='-' )\n",
    "\n",
    "\n",
    "    plt.plot( pf_plt, pf_num[:,0], color=col[7], linewidth=2, linestyle='-')\n",
    "\n",
    "\n",
    "    #for i in range(G):\n",
    "    #    plt.text( pf_plt[i], -80 + 5*i, '%5g' % pf_num[i,0], color=col[7], fontsize=14, fontweight='bold')\n",
    "    #for p in range(P):\n",
    "    #    plt.plot( pf_grp, pf_25[:,p], color=col[p], linewidth=1.5, linestyle='--' )\n",
    "    #    plt.plot( pf_grp, pf_75[:,p], color=col[p], linewidth=1.5, linestyle='--' )\n",
    "    #    plt.plot( pf_grp, pf_min[:,p], color=col[p], linewidth=1.5, linestyle=':' )\n",
    "    #    plt.plot( pf_grp, pf_max[:,p], color=col[p], linewidth=1.5, linestyle=':' )\n",
    "\n",
    "    plt.plot([0,400],[0,400],linestyle='--',linewidth=1.5, color='black')\n",
    "\n",
    "    plt.legend(pf_header, loc='best')\n",
    "    plt.xlabel('PaO2/FiO2 (truth)',fontsize=14)\n",
    "    plt.ylabel('PaO2/FiO2 (predicted)',fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter out bad data and SpO2s > 96\n",
    "idxIgnore = np.any([df.fio2.values < 20, df.fio2.values > 100, df.sao2.values > 96], axis=0)\n",
    "\n",
    "# extract data\n",
    "y = df.pao2[~idxIgnore].values\n",
    "X_names = ['sao2', 'fio2', 'vasopressor','peep','tidalvolume','peakpressure']\n",
    "\n",
    "# create an iterator to get index of these names\n",
    "idx = [i for i in range(df.columns.values.size) if df.columns[i] in X_names]\n",
    "\n",
    "# get feature/predictor matrix as numpy array\n",
    "X = df[idx].values\n",
    "X = X[~idxIgnore,:]\n",
    "\n",
    "# create the header from the column index we made earlier\n",
    "X_header = [df.columns[i] for i in idx]\n",
    "\n",
    "# Add in the sao2/fio2\n",
    "z = X[:, X_header.index('sao2')] / X[:, X_header.index('fio2')]\n",
    "X = np.column_stack([X, z])\n",
    "X_header.extend(['sao2fio2'])\n",
    "\n",
    "# Add in the predicted pao2 from the non-linear equation\n",
    "z = pao2_nonlinear(X[:, X_header.index('sao2')]) # / X[:, X_header.index('fio2')]\n",
    "X = np.column_stack([X, z])\n",
    "X_header.extend(['pao2_nonlinear'])\n",
    "\n",
    "## Add in the predicted pao2/fio2 from the non-linear equation\n",
    "#z = pao2_nonlinear(X[:, X_header.index('sao2')])  / X[:, X_header.index('fio2')]\n",
    "#X = np.column_stack([X, z])\n",
    "#X_header.extend(['pao2fio2_nonlinear'])\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X_train)\n",
    "\n",
    "# using the fixed equations (linear/loglinear/nonlinear), calculate the pao2\n",
    "sao2 = X_test[:, X_header.index('sao2')]\n",
    "fio2 = X_test[:, X_header.index('fio2')] / 100\n",
    "\n",
    "pf1 = pao2_nonlinear(sao2) / fio2\n",
    "pf2 = pao2_loglinear(sao2,fio2) / fio2\n",
    "pf3 = pao2_linear(sao2,fio2) / fio2\n",
    "\n",
    "# ground truth\n",
    "sf = sao2 / fio2\n",
    "pf = y_test / fio2\n",
    "\n",
    "\n",
    "# train model\n",
    "\n",
    "fio2_train = X_train[:, X_header.index('fio2')] / 100\n",
    "yhat_xg = try_xgboost(imp.transform(X_train), y_train, imp.transform(X_test), y_test, feature_names=X_header)\n",
    "pf_pred = yhat_xg / fio2\n",
    "\n",
    "#============ CREATE DATA FOR PLOTS ====================#\n",
    "pf_dict = {'Linear': pf3,\n",
    "          'Log-linear': pf2,\n",
    "          'Non-linear': pf1,\n",
    "          'Model': pf_pred}\n",
    "\n",
    "make_boxplot(pf, pf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter out bad data and SpO2s > 96\n",
    "idxIgnore = np.any([df.fio2.values < 20, df.fio2.values > 100, df.sao2.values > 96], axis=0)\n",
    "\n",
    "# extract data\n",
    "y = df.pao2[~idxIgnore].values\n",
    "X_names = ['sao2', 'fio2', 'vasopressor','peep', 'tidalvolume', 'peakpressure']\n",
    "\n",
    "# create an iterator to get index of these names\n",
    "idx = [i for i in range(df.columns.values.size) if df.columns[i] in X_names]\n",
    "\n",
    "# get feature/predictor matrix as numpy array\n",
    "X = df[idx].values\n",
    "X = X[~idxIgnore,:]\n",
    "\n",
    "# create the header from the column index we made earlier\n",
    "X_header = [df.columns[i] for i in idx]\n",
    "\n",
    "\n",
    "# Add in the sao2/fio2\n",
    "z = X[:, X_header.index('sao2')] / X[:, X_header.index('fio2')]\n",
    "X = np.column_stack([X, z])\n",
    "X_header.extend(['sao2fio2'])\n",
    "\n",
    "## Add in the predicted pao2/fio2 from the non-linear equation\n",
    "#z = pao2_nonlinear(X[:, X_header.index('sao2')])  / X[:, X_header.index('fio2')]\n",
    "#X = np.column_stack([X, z])\n",
    "#X_header.extend(['pao2fio2_nonlinear'])\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X_train)\n",
    "\n",
    "# using the fixed equations (linear/loglinear/nonlinear), calculate the pao2\n",
    "sao2 = X_test[:, X_header.index('sao2')]\n",
    "fio2 = X_test[:, X_header.index('fio2')] / 100\n",
    "\n",
    "pf1 = pao2_nonlinear(sao2) / fio2\n",
    "pf2 = pao2_loglinear(sao2,fio2) / fio2\n",
    "pf3 = pao2_linear(sao2,fio2) / fio2\n",
    "\n",
    "# ground truth\n",
    "sf = sao2 / fio2\n",
    "pf = y_test / fio2\n",
    "\n",
    "#============ BUILD PREDICTIVE MODEL ===============#\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None,\n",
    "                                    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                                    max_features=2, max_leaf_nodes=None, bootstrap=True,\n",
    "                                    oob_score=False, n_jobs=1, random_state=None,\n",
    "                                    verbose=0, warm_start=False, class_weight=None)\n",
    "rf.fit( imp.transform(X_train) , y_train )\n",
    "yhat = rf.predict(imp.transform(X_test))\n",
    "rf_pred = yhat / fio2\n",
    "\n",
    "\n",
    "# linear regression\n",
    "model = lm.LinearRegression(fit_intercept=True)\n",
    "model.fit( imp.transform(X_train) , y_train )\n",
    "yhat = model.predict(imp.transform(X_test))\n",
    "lr_pred = yhat / fio2\n",
    "\n",
    "# xgboost\n",
    "yhat_xg, bst = try_xgboost(imp.transform(X_train), y_train, imp.transform(X_test), y_test,\n",
    "                      feature_names=X_header)\n",
    "xg_pred = yhat_xg / fio2\n",
    "\n",
    "#============ CREATE DATA FOR PLOTS ====================#\n",
    "pf_dict = {'Linear': pf3,\n",
    "          'Log-linear': pf2,\n",
    "          'Non-linear': pf1,\n",
    "          'Regression': lr_pred,\n",
    "          'Random Forest': rf_pred,\n",
    "          'XGBoost': xg_pred}\n",
    "\n",
    "make_boxplot(pf, pf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_fig = xgb.to_graphviz(bst, num_trees=2)\n",
    "xgb_fig.render(filename='xgb_graph', view=True) # view in pdf reader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
